{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.loader import DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "import inspect, random, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import Chem\n",
    "from multiprocessing import Pool\n",
    "from rdkit.Chem import Draw, PandasTools\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score, roc_auc_score, average_precision_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from torch_geometric.nn.aggr import AttentionalAggregation\n",
    "import torch\n",
    "from modules.som_dataset import CustomDataset\n",
    "# from models.som_models import GNNSOM\n",
    "from modules.som_models import GNNSOM\n",
    "from utils import validation\n",
    "from tabulate import tabulate\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from collections import defaultdict\n",
    "from glob import glob\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', '.*Sparse CSR tensor support is in beta state.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def save_json(json_path, dict_file):\n",
    "    with open(json_path, 'w') as file:\n",
    "        json.dump(dict_file, file)\n",
    "\n",
    "def load_json(json_path):\n",
    "    with open(json_path, \"r\") as st_json:\n",
    "        json_obj = json.load(st_json)\n",
    "    return json_obj   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_interval(data, confidence=0.95):\n",
    "    n = len(data)\n",
    "    m = np.mean(data)\n",
    "    se = stats.sem(data)\n",
    "    h = se * stats.t.ppf((1 + confidence) / 2., n - 1)\n",
    "            \n",
    "    lower_bound = max(m - h, 0)\n",
    "    mean = max(m, 0)\n",
    "    upper_bound = max(m + h, 0)\n",
    "    return lower_bound, mean, upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_csv(path, table_data, headers):\n",
    "    score_logs = tabulate(table_data, headers, tablefmt=\"tsv\")\n",
    "    text_file=open(path,\"w\")\n",
    "    text_file.write(score_logs)\n",
    "    text_file.close()\n",
    "    df = pd.read_csv(path, sep='\\t')\n",
    "    df.to_csv(path, index=None)\n",
    "\n",
    "def get_logs(scores, cyp_list, args):        \n",
    "    logs = ''\n",
    "    table_data1 = []\n",
    "    table_data2 = []\n",
    "    table_data3 = []\n",
    "    table_data4 = []\n",
    "    for cyp in cyp_list:        \n",
    "        headers1 = ['CYP', \n",
    "                   'auc_subs', 'apc_subs', 'f1s_subs', 'rec_subs', 'prc_subs', 'n_subs',                    \n",
    "                   ]\n",
    "        \n",
    "        headers2 = ['CYP',\n",
    "                    'jac_bond', 'f1s_bond', 'apc_bond', 'n_bond',\n",
    "                    'jac_spn', 'f1s_spn', 'apc_spn', 'n_spn',                    \n",
    "                    'jac_som', 'f1s_som', 'apc_som', 'n_som',\n",
    "                    ]   \n",
    "        headers3 = ['CYP', \n",
    "                    'jac_oxi', 'f1s_oxi', 'apc_oxi', 'n_oxi',\n",
    "                    'jac_clv', 'f1s_clv', 'apc_clv',  'n_clv',\n",
    "                    'jac_hdx', 'f1s_hdx', 'apc_hdx', 'n_hdx',\n",
    "                    'jac_rdc', 'f1s_rdc', 'apc_rdc',  'n_rdc', \n",
    "\n",
    "                    ]        \n",
    "        headers4 = ['CYP',\n",
    "                    'n_subs', 'n_bond', 'n_spn', 'n_hdx', 'n_oxi', 'n_clv', 'n_rdc', 'n_som'\n",
    "                    ]          \n",
    "        row1, row2, row3, row4 = [cyp], [cyp], [cyp], [cyp]\n",
    "        for header in headers1[1:]:\n",
    "            if 'loss' in header or header[:2] == 'n_':\n",
    "                row1.append(scores[cyp][header])\n",
    "            else:\n",
    "                row1.append(scores[cyp][args.th][header])\n",
    "                \n",
    "                \n",
    "        for header in headers2[1:]:\n",
    "            if 'loss' in header or header[:2] == 'n_':\n",
    "                row2.append(scores[cyp][header])\n",
    "            else:\n",
    "                row2.append(scores[cyp][args.th][header])\n",
    "        \n",
    "        for header in headers3[1:]:\n",
    "            if 'loss' in header or header[:2] == 'n_':\n",
    "                row3.append(scores[cyp][header])\n",
    "            else:\n",
    "                row3.append(scores[cyp][args.th][header])\n",
    "\n",
    "        for header in headers4[1:]:\n",
    "            if 'loss' in header or header[:2] == 'n_':\n",
    "                row4.append(scores[cyp][header])\n",
    "            else:\n",
    "                row4.append(scores[cyp][args.th][header])\n",
    "\n",
    "        table_data1.append(row1)\n",
    "        table_data2.append(row2)\n",
    "        table_data3.append(row3)        \n",
    "        table_data4.append(row4)        \n",
    "\n",
    "    logs += (tabulate(table_data1, headers1, tablefmt=\"grid\", floatfmt=\".4f\") + '\\n')\n",
    "    logs += (tabulate(table_data2, headers2, tablefmt=\"grid\", floatfmt=\".4f\") + '\\n')\n",
    "    logs += (tabulate(table_data3, headers3, tablefmt=\"grid\", floatfmt=\".4f\") + '\\n')\n",
    "    logs += tabulate(table_data4, headers4, tablefmt=\"grid\", floatfmt=\".4f\")\n",
    "\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CYP_REACTION(x):\n",
    "    cyp_col = ['BOM_1A2', 'BOM_2A6', 'BOM_2B6', 'BOM_2C8', 'BOM_2C9', 'BOM_2C19', 'BOM_2D6', 'BOM_2E1', 'BOM_3A4']\n",
    "    cyp_reactions = x[cyp_col].tolist()\n",
    "    cyp_reactions = [i for i in cyp_reactions if i] \n",
    "    return '\\n'.join( cyp_reactions )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    'auc_subs', 'apc_subs', 'f1s_subs', 'rec_subs', 'prc_subs',\n",
    "    'jac_bond', 'f1s_bond', 'prc_bond', 'rec_bond', 'auc_bond', 'apc_bond',\n",
    "    'jac_spn', 'f1s_spn', 'prc_spn', 'rec_spn', 'auc_spn', 'apc_spn',\n",
    "    'jac_hdx', 'f1s_hdx', 'prc_hdx', 'rec_hdx', 'auc_hdx', 'apc_hdx',\n",
    "    'jac_oxi', 'f1s_oxi', 'prc_oxi', 'rec_oxi', 'auc_oxi', 'apc_oxi',\n",
    "    'jac_clv', 'f1s_clv', 'prc_clv', 'rec_clv', 'auc_clv', 'apc_clv',    \n",
    "    'jac_rdc', 'f1s_rdc', 'prc_rdc', 'rec_rdc', 'auc_rdc', 'apc_rdc',\n",
    "    'jac_som', 'f1s_som', 'prc_som', 'rec_som', 'auc_som', 'apc_som',]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyp_list = [f'BOM_{i}' for i in  '1A2 2A6 2B6 2C8 2C9 2C19 2D6 2E1 3A4'.split()] + ['CYP_REACTION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONFIG:\n",
    "    substrate_loss_weight = 0.33    \n",
    "    bond_loss_weight = 0.33\n",
    "    atom_loss_weight = 0.33\n",
    "    som_type_loss_weight = 0.33\n",
    "    class_type = 2    \n",
    "    th = 0.1    \n",
    "    substrate_th = 0.5\n",
    "    adjust_substrate = False\n",
    "    average = 'binary'    \n",
    "    equivalent_bonds_mean = True\n",
    "    train_only_spn_H_atom = False    \n",
    "    device = 'cuda:0'\n",
    "    test_only_reaction_mol = False\n",
    "    drop_node_p = 0.0\n",
    "    mask_node_p = 0.0\n",
    "    filt_som = 0\n",
    "    equivalent_mean = False\n",
    "    reduction = 'sum'\n",
    "    n_classes = 5\n",
    "args = CONFIG()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GNNSOM(\n",
    "            num_layers=2,\n",
    "            gnn_num_layers = 8,\n",
    "            pooling='sum',\n",
    "            dropout=0.1, \n",
    "            cyp_list=cyp_list, \n",
    "            use_face = True, \n",
    "            node_attn = True,\n",
    "            face_attn = True,            \n",
    "            n_classes=args.n_classes,\n",
    "            use_som_v2=True\n",
    "            ).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = PandasTools.LoadSDF('data/train_nonreact_0611.sdf')\n",
    "df['CYP_REACTION'] = df.apply(CYP_REACTION, axis=1)\n",
    "df['POS_ID'] = 'TRAIN' + df.index.astype(str).str.zfill(4)\n",
    "\n",
    "# train_dataset = CustomDataset(df=df, class_type=2, cyp_list=cyp_list, args=args, add_H=True)\n",
    "# train_loader = DataLoader(train_dataset, num_workers=2, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/torch_geometric/data/dataset.py:217: UserWarning: The `pre_filter` argument differs from the one used in the pre-processed version of this dataset. If you want to make use of another pre-fitering technique, make sure to delete '{self.processed_dir}' first\n",
      "  warnings.warn(\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "test_df = PandasTools.LoadSDF('data/test_0611.sdf')\n",
    "test_df['CYP_REACTION'] = test_df.apply(CYP_REACTION, axis=1)\n",
    "test_df['POS_ID'] = 'TEST' + test_df.index.astype(str).str.zfill(4)\n",
    "\n",
    "# test_df = test_df[test_df['InChIKey'] != ''].reset_index(drop=True)\n",
    "\n",
    "test_dataset = CustomDataset(df=test_df, cyp_list=cyp_list, args=args)\n",
    "test_loader = DataLoader(test_dataset, num_workers=2, batch_size=8, shuffle=False)\n",
    "\n",
    "loss_fn_ce, loss_fn_bce = torch.nn.CrossEntropyLoss(), torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn_bce = torch.nn.BCEWithLogitsLoss()\n",
    "loss_fn_ce = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 신뢰구간별"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_scores(validator, args):\n",
    "    scores = {}\n",
    "\n",
    "    if args.adjust_substrate:\n",
    "        validator.adjust_substrate(args.substrate_th)\n",
    "\n",
    "    tasks = ['subs', 'bond', 'atom',  'spn', 'hdx', 'clv', 'oxi', 'rdc', 'som']\n",
    "    metrics = ['jac','f1s','prc','rec','auc', 'apc']\n",
    "\n",
    "    if args.equivalent_mean:\n",
    "        validator.unbatch()\n",
    "        validator.eq_mean()\n",
    "\n",
    "    for cyp in model.cyp_list:\n",
    "        scores[cyp] = {}        \n",
    "        \n",
    "        for task in tasks:\n",
    "            y_true, y_prob = validator.get_probs(task, cyp)\n",
    "            scores[cyp][f'n_{task}'] = f'{int(sum(y_true))} / {len(y_true)}'\n",
    "\n",
    "            if task == 'subs':\n",
    "                task_scores = validator.get_scores(task=task, cyp=cyp, average=args.average, th=args.substrate_th)\n",
    "            else:\n",
    "                task_scores = validator.get_scores(task=task, cyp=cyp, average=args.average, th=args.th)\n",
    "\n",
    "            for mname, tscore in zip(metrics, task_scores):\n",
    "                scores[cyp][f'{mname}_{task}'] = tscore\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args.ckpt = f'ckpt/0_reduction_sum_v2_dout01.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:979: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "  0%|          | 0/30 [00:08<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for seed in tqdm(range(30)):        \n",
    "    args.ckpt = f'ckpt/{seed}.pt'    \n",
    "    args.ckpt = f'ckpt/29_w50_25_25_hdxall_bs16_v2.pt'\n",
    "    \n",
    "    model.load_state_dict(torch.load(args.ckpt, 'cpu'))\n",
    "    \n",
    "    args.add_H = True\n",
    "\n",
    "    seed_df = []\n",
    "    \n",
    "    test_scores = validation(model, test_loader, loss_fn_ce, loss_fn_bce, args)\n",
    "    validator = test_scores['validator'] \n",
    "    for th in [0.1, 0.15, 0.2, 0.3]:\n",
    "        args.th = th\n",
    "        scores = cal_scores(validator, args)\n",
    "        for cyp in cyp_list:\n",
    "            for metric in metrics:\n",
    "                seed_df.append({'cyp' : cyp, 'seed' : seed, 'metric' : metric, 'score' : scores[cyp][metric], 'threshold' : th})\n",
    "\n",
    "    seed_df = pd.DataFrame(seed_df)\n",
    "    seed_df.to_csv(f'infer/seed/{seed}.csv', index=None)\n",
    "    break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_df_dict = {}\n",
    "for seed in range(30):    \n",
    "    seed_df = pd.read_csv(f'infer/seed/{seed}.csv', index_col=None)\n",
    "    seed_df_dict[seed] = seed_df\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_type = [\n",
    "    ( 'substrate',['auc_subs', 'apc_subs', 'f1s_subs', 'rec_subs', 'prc_subs', 'n_subs']),\n",
    "    ( 'bond' ,['jac_bond', 'f1s_bond', 'prc_bond', 'rec_bond', 'auc_bond', 'apc_bond', 'n_bond']),    \n",
    "    ( 'SPN-Oxidation' ,['jac_spn', 'f1s_spn', 'prc_spn', 'rec_spn', 'auc_spn', 'apc_spn', 'n_spn']),\n",
    "\n",
    "    ( 'Hydroxylation' ,['jac_hdx', 'f1s_hdx', 'prc_hdx', 'rec_hdx', 'auc_hdx', 'apc_hdx', 'n_hdx']),\n",
    "    ( 'Oxidation' ,['jac__oxi', 'f1s__oxi', 'prc__oxi', 'rec__oxi', 'auc__oxi', 'apc__oxi', 'n__oxi']),\n",
    "    ( 'Cleavage' ,['jac_clv', 'f1s_clv', 'prc_clv', 'rec_clv', 'auc_clv', 'apc_clv', 'n_clv']),\n",
    "    ( 'Reducion' ,['jac_nn_rdc', 'f1s_nn_rdc', 'prc_nn_rdc', 'rec_nn_rdc', 'auc_nn_rdc', 'apc_nn_rdc', 'n_nn_rdc']),    \n",
    "    ( 'Site-of-metabolism' ,['jac_som', 'f1s_som', 'prc_som', 'rec_som', 'auc_som', 'apc_som', 'n_som'],   ) \n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 시드 30개의 신뢰구간 성능\n",
    "# th = 0.15\n",
    "# args.th = th\n",
    "\n",
    "# ci_scores = scores.copy()\n",
    "\n",
    "# for cyp in tqdm(cyp_list):\n",
    "#     ci_scores[cyp][th] = {}\n",
    "#     for metric in metrics:\n",
    "#         score_value = []\n",
    "#         for seed in seed_df_dict.keys():\n",
    "#             score_value.append(seed_df_dict[seed].query('cyp==@cyp').query('metric==@metric').query('threshold==@th').score.item())\n",
    "#         s, m, l = confidence_interval(score_value)\n",
    "#         ci_scores[cyp][th][metric] = m\n",
    "#         # ci_scores[cyp][th][metric] =  f'{m:.4f}({s:.2f}-{l:.2f})'\n",
    "# print(get_logs(ci_scores, cyp_list, args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/numpy/core/_methods.py:269: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/pjh/anaconda3/envs/crash/lib/python3.8/site-packages/numpy/core/_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# seed 평균 저장 (시각화 용)\n",
    "\n",
    "for th in [0.1, 0.15, 0.2, 0.3]:    \n",
    "    score_df = []\n",
    "\n",
    "    for cyp in cyp_list:    \n",
    "        for metric in metrics:\n",
    "            \n",
    "            score_value = []\n",
    "            for seed in seed_df_dict.keys():\n",
    "                score_value.append(seed_df_dict[seed].query('cyp==@cyp').query('metric==@metric').query('threshold==@th').score.item())\n",
    "            _,score,_ = confidence_interval(score_value)\n",
    "            score_df.append({'cyp' : cyp, 'metric' : metric, 'score' : score})\n",
    "    score_df = pd.DataFrame(score_df)\n",
    "    score_df.to_csv( f'scores/GNN-CYPSOM_{th}.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +----------+------------+------------+------------+------------+-----------+-----------+-----------+----------+-----------+-----------+-----------+------------+\n",
    "# | CYP      |   jac_bond |   f1s_bond |   apc_bond | n_bond     |   jac_spn |   f1s_spn |   apc_spn | n_spn    |   jac_som |   f1s_som |   apc_som | n_som      |\n",
    "# +==========+============+============+============+============+===========+===========+===========+==========+===========+===========+===========+============+\n",
    "# | BOM_1A2  |     0.1088 |     0.1962 |     0.0745 | 106 / 5772 |    0.3636 |    0.5333 |    0.3882 | 5 / 399  |    0.1200 |    0.2143 |    0.0871 | 111 / 6171 |\n",
    "# +----------+------------+------------+------------+------------+-----------+-----------+-----------+----------+-----------+-----------+-----------+------------+\n",
    "# | BOM_2A6  |     0.0897 |     0.1647 |     0.0397 | 40 / 5772  |    0.4286 |    0.6000 |    0.4429 | 3 / 399  |    0.1176 |    0.2105 |    0.0652 | 43 / 6171  |\n",
    "# +----------+------------+------------+------------+------------+-----------+-----------+-----------+----------+-----------+-----------+-----------+------------+\n",
    "# | BOM_2B6  |     0.0519 |     0.0988 |     0.0281 | 49 / 5772  |    0.2727 |    0.4286 |    0.2372 | 5 / 399  |    0.0667 |    0.1250 |    0.0434 | 54 / 6171  |\n",
    "# +----------+------------+------------+------------+------------+-----------+-----------+-----------+----------+-----------+-----------+-----------+------------+\n",
    "# | BOM_2C8  |     0.0783 |     0.1453 |     0.0458 | 91 / 5772  |    0.2000 |    0.3333 |    0.1644 | 3 / 399  |    0.0837 |    0.1545 |    0.0467 | 94 / 6171  |\n",
    "# +----------+------------+------------+------------+------------+-----------+-----------+-----------+----------+-----------+-----------+-----------+------------+\n",
    "# | BOM_2C9  |     0.0930 |     0.1702 |     0.0585 | 82 / 5772  |    0.5455 |    0.7059 |    0.4431 | 7 / 399  |    0.1150 |    0.2063 |    0.0776 | 89 / 6171  |\n",
    "# +----------+------------+------------+------------+------------+-----------+-----------+-----------+----------+-----------+-----------+-----------+------------+\n",
    "# | BOM_2C19 |     0.1045 |     0.1892 |     0.0619 | 79 / 5772  |    0.4167 |    0.5882 |    0.5252 | 7 / 399  |    0.1221 |    0.2176 |    0.0829 | 86 / 6171  |\n",
    "# +----------+------------+------------+------------+------------+-----------+-----------+-----------+----------+-----------+-----------+-----------+------------+\n",
    "# | BOM_2D6  |     0.1461 |     0.2549 |     0.1762 | 133 / 5772 |    0.6364 |    0.7778 |    0.7828 | 8 / 399  |    0.1655 |    0.2840 |    0.2078 | 141 / 6171 |\n",
    "# +----------+------------+------------+------------+------------+-----------+-----------+-----------+----------+-----------+-----------+-----------+------------+\n",
    "# | BOM_2E1  |     0.0702 |     0.1311 |     0.0793 | 47 / 5772  |    0.2000 |    0.3333 |    0.1925 | 4 / 399  |    0.0806 |    0.1493 |    0.0888 | 51 / 6171  |\n",
    "# +----------+------------+------------+------------+------------+-----------+-----------+-----------+----------+-----------+-----------+-----------+------------+\n",
    "# | BOM_3A4  |     0.1531 |     0.2655 |     0.1742 | 276 / 5772 |    0.3889 |    0.5600 |    0.4039 | 14 / 399 |    0.1631 |    0.2805 |    0.1814 | 290 / 6171 |\n",
    "# +----------+------------+------------+------------+------------+-----------+-----------+-----------+----------+-----------+-----------+-----------+------------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +----------+-----------+-----------+-----------+------------+-----------+-----------+-----------+------------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+----------+\n",
    "# | CYP      |   jac_hdx |   f1s_hdx |   apc_hdx | n_hdx      |   jac_oxi |   f1s_oxi |   apc_oxi | n_oxi      |   jac_clv |   f1s_clv |   apc_clv | n_clv     |   jac_rdc |   f1s_rdc |   apc_rdc | n_rdc    |\n",
    "# +==========+===========+===========+===========+============+===========+===========+===========+============+===========+===========+===========+===========+===========+===========+===========+==========+\n",
    "# | BOM_1A2  |    0.0959 |    0.1750 |    0.1147 | 56 / 1995  |    0.0893 |    0.1639 |    0.0500 | 43 / 5772  |    0.1208 |    0.2156 |    0.0841 | 37 / 3777 |    0.0000 |    0.0000 |    0.0005 | 2 / 3777 |\n",
    "# +----------+-----------+-----------+-----------+------------+-----------+-----------+-----------+------------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+----------+\n",
    "# | BOM_2A6  |    0.1429 |    0.2500 |    0.1487 | 17 / 1995  |    0.0833 |    0.1538 |    0.0643 | 19 / 5772  |    0.0833 |    0.1538 |    0.0398 | 21 / 3777 |   -1.0000 |    0.0000 |   -0.0000 | 0 / 3777 |\n",
    "# +----------+-----------+-----------+-----------+------------+-----------+-----------+-----------+------------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+----------+\n",
    "# | BOM_2B6  |    0.1111 |    0.2000 |    0.1038 | 24 / 1995  |    0.0588 |    0.1111 |    0.0267 | 22 / 5772  |    0.0309 |    0.0600 |    0.0096 | 17 / 3777 |   -1.0000 |    0.0000 |   -0.0000 | 0 / 3777 |\n",
    "# +----------+-----------+-----------+-----------+------------+-----------+-----------+-----------+------------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+----------+\n",
    "# | BOM_2C8  |    0.0676 |    0.1266 |    0.0730 | 59 / 1995  |    0.0714 |    0.1333 |    0.0329 | 31 / 5772  |    0.0902 |    0.1654 |    0.0642 | 26 / 3777 |   -1.0000 |    0.0000 |   -0.0000 | 0 / 3777 |\n",
    "# +----------+-----------+-----------+-----------+------------+-----------+-----------+-----------+------------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+----------+\n",
    "# | BOM_2C9  |    0.1311 |    0.2319 |    0.1181 | 46 / 1995  |    0.0698 |    0.1304 |    0.0295 | 31 / 5772  |    0.0833 |    0.1538 |    0.0623 | 23 / 3777 |    0.0000 |    0.0000 |    0.0008 | 3 / 3777 |\n",
    "# +----------+-----------+-----------+-----------+------------+-----------+-----------+-----------+------------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+----------+\n",
    "# | BOM_2C19 |    0.1200 |    0.2143 |    0.1058 | 43 / 1995  |    0.0882 |    0.1622 |    0.0747 | 31 / 5772  |    0.1181 |    0.2113 |    0.1049 | 27 / 3777 |    0.0000 |    0.0000 |    0.0005 | 2 / 3777 |\n",
    "# +----------+-----------+-----------+-----------+------------+-----------+-----------+-----------+------------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+----------+\n",
    "# | BOM_2D6  |    0.0851 |    0.1569 |    0.1006 | 77 / 1995  |    0.0690 |    0.1290 |    0.0687 | 48 / 5772  |    0.1597 |    0.2754 |    0.2597 | 45 / 3777 |    0.0000 |    0.0000 |    0.0008 | 3 / 3777 |\n",
    "# +----------+-----------+-----------+-----------+------------+-----------+-----------+-----------+------------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+----------+\n",
    "# | BOM_2E1  |    0.1034 |    0.1875 |    0.1498 | 21 / 1995  |    0.0286 |    0.0556 |    0.0378 | 24 / 5772  |    0.0702 |    0.1311 |    0.0722 | 13 / 3777 |    0.0000 |    0.0000 |    0.0005 | 2 / 3777 |\n",
    "# +----------+-----------+-----------+-----------+------------+-----------+-----------+-----------+------------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+----------+\n",
    "# | BOM_3A4  |    0.0606 |    0.1143 |    0.1436 | 146 / 1995 |    0.0492 |    0.0938 |    0.0565 | 112 / 5772 |    0.2000 |    0.3333 |    0.1647 | 97 / 3777 |    0.0000 |    0.0000 |    0.0577 | 9 / 3777 |\n",
    "# +----------+-----------+-----------+-----------+------------+-----------+-----------+-----------+------------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+----------+"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crash",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
